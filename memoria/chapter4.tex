\cleardoublepage

\chapter{Exploración del modelo predictivo}
\label{makereference4}

\section{Introducción a los modelos predictivos}
\label{makereference4.1}

Cuando hablamos de modelos predictivos nos estamos refiriendo al análisis que agrupa una serie de técnicas para conseguir analizar datos reales tanto actuales como históricos y así conseguir predicciones. Con esta predicción podremos saber cuanto se acerca nuestra predicción a la realidad.

\section{Descripción de las librerías usadas}
\label{makereference4.2}
	\subsection{Scikit-learn}
	\label{makereference4.2.1}
	Scikit-learn es una biblioteca de aprendizaje de software libre para el lenguaje de programación Python. Cuenta con varios algoritmos de clasificación, regresión y agrupación, incluyendo máquinas de vector de apoyo, bosques aleatorios, aumento de gradiente, k-medios y DBSCAN, y está diseñado para interoperar con las bibliotecas numéricas y científicas Python NumPy y SciPy. (\cite{ARP:Scikit:2017})
	
	\subsection{NumPy}
	\label{makereference4.2.2}
	NumPy es una extensión de Python, que le agrega mayor soporte para vectores y matrices, constituyendo una biblioteca de funciones matemáticas de alto nivel para operar con esos vectores o matrices. (\cite{ARP:Numpy:2017})
	
	\subsection{SciPy}
	\label{makereference4.2.3}
	SciPy es una biblioteca open source de herramientas y algoritmos matemáticos para Python. SciPy contiene módulos para optimización, álgebra lineal, integración, interpolación, funciones especiales, FFT, procesamiento de señales y de imagen, resolución de ODEs y otras tareas para la ciencia e ingeniería. (\cite{ARP:Scipy:2017})
	
\section{Algoritmos utilizados}
\label{makereference4.3}
	\subsection{Regresión Lineal}
	\label{makereference4.3.1}

	La \textbf{regresión lineal} es un modelo matemático que trata de hallar los coeficientes de una \textbf{combinación lineal} que mejor se ajusten a un conjunto de puntos dispersos conocidos a través del método de los \textbf{mínimos cuadrados}. Esto es, trazar una línea en el espacio que pase lo más próximo posible a todos los puntos.

	Al conocer dicha función lineal, podremos \textbf{``predecir''} con cierto grado de exactitud, lo que pasará.

	\begin{figure}[htb]
		
		\begin{center}
			\includegraphics[height=3.5in]{figures/regression.png}
			\caption{Regresión lineal [Fuente: \href{www.wikipedia.org}{Wikipedia}]}
		\end{center}
		
		\label{regression}
	\end{figure}
	
	La recta que se puede ver en la gráfica \ref{regression}, muestra cómo la \textbf{regresión lineal} intenta dibujar una línea que minimice mejor la suma residual de cuadrados entre las respuestas observadas en el conjunto de datos, y las respuestas predichas por la aproximación lineal.
	También se calculan los coeficientes, la suma residual de cuadrados y el puntaje de varianza.

	\subsection{SVR (Support Vector Regression)}
	\label{makereference4.3.2}

	SRV es una nueva versión de SVM para regresión. SVM es un algoritmo de aprendizaje supervisado de la familia de los \textbf{clasificadores}.

	El término \textbf{clasificador} se utiliza en referencia al algoritmo utilizado para asignar un elemento entrante no etiquetado en una categoría concreta conocida. Dicho algoritmo, permite pues, ordenar o disponer por clases elementos entrantes, a partir de cierta información característica de estos.

	En SVM los datos son etiquetados en distintas clases y el clasificador intentará construir un hiperplano o conjunto de hiperplanos dentro del conjunto de datos que mejor separe las clases unas de otras. Ver figura \ref{svm}.

	\begin{figure}[htb]
		
		\begin{center}
			\includegraphics[height=3.5in]{figures/svm.jpg}
			\caption{SVM [Fuente: \href{www.wikipedia.org}{Wikipedia}]}
		\end{center}
		\label{svm}
	\end{figure}

	Las características más notables de los clasificadores SVM son:
	\begin{itemize}
		\item Proyectar previamente los datos a un espacio de dimensionalidad superior.
		\item Buscar el hiperplano que tenga la máxima distancia con los puntos que estén más cerca de él mismo. Es decir, que dejen una mayor margen entre los datos.
	\end{itemize}

	La diferencia entre SVR y SVM es que SVR intenta hacer una regresión a partir de el clasificador. Para esto, realiza un mapeo no lineal de los datos del entrenamiento a un espacio de mayor dimensión, donde podremos realizar una regresión lineal. Ver figura \ref{svr}.

	\begin{figure}[htb]
		\begin{center}
			\includegraphics[height=3.5in]{figures/svr.png}
			\caption{SVR [Fuente: \href{http://scikit-learn.org/stable/auto_examples/svm/plot_svm_regression.html}{scikit learn}] }
		\end{center}
		\label{svr}
	\end{figure}
	
	\subsection{Redes Neuronales}
	\label{makereference4.3.3}
	.
	\begin{figure}[htb]
		
		\begin{center}
			\includegraphics[height=4.5in]{figures/neuronal_network.png}
			\caption{Red neuronal [Fuente: \href{www.scikit-learn.org}{scikit-learn}]}
		\end{center}
		
		\label{network}
	\end{figure}

	Las \textbf{redes neuronales} son un algoritmo de aprendizaje supervisado. Suelen consistir en varias capas ocultas donde la señal se propaga de adelante hacia atrás.
	
	A partir de X características se obtiene una función f(X).
	
\section{Método del estudio}
\label{makereference4.4}

\section{Modelo escogido}
\label{makereference4.5}
%TODO explicar el modelo elegido